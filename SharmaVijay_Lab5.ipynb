{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 3. Pandas, метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Vijay Sharma\n",
    "\n",
    "Student ID: 16BD02047\n",
    "\n",
    "Email: vijay11fce@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.neighbors\n",
    "import sklearn.ensemble as ensemble\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на вопросы о данных по авиарейсам в США.\n",
    "\n",
    "Данные: http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n",
    "(обратите внимание, что распаковывать этот файл не обязательно — функция `pandas.read_csv` умеет читать из архивов автоматически)\n",
    "\n",
    "Описание: http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "1. Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)\n",
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом.\n",
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?\n",
    "4. Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?\n",
    "5. Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?\n",
    "6. Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2008.csv.bz2\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.Какая из причин отмены рейса (CancellationCode) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2008.csv.bz2\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CC = df['CancellationCode']\n",
    "CC.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2. Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Max: \", df.Distance.max())\n",
    "print(\"Min: \", df.Distance.min())\n",
    "print(\"Mean: \", df.Distance.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3. Не выглядит ли подозрительным минимальное пройденное расстояние. В какие дни и на каких рейсах оно было.Какое расстояние было пройдено этими же рейсами в другие дни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.Distance == df.Distance.min()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[DF.FlightNum == 4988]['Distance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.FlightNum == 5572]['Distance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Из какого аэропорта было произведено больше всего вылетов. В каком городе он находится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"Origin\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Найдите для каждого аэропорта среднее время полета (AirTime) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"Origin\")['AirTime'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Max mean air time: \", DF.groupby(\"Origin\")['AirTime'].mean().argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Найдите аэропорт, у которого наибольшая доля задержанных (DepDelay > 0) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию filter после groupby)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DFGB = DF.groupby(\"Origin\")['DepDelay']\n",
    "DFGB_Filtered = DF[DF.DepDelay > 0].groupby(\"Origin\")['DepDelay']\n",
    "(DFGB_Filtered.count() / DFGB.count() * (DFGB.count() >= 1000)).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: метрические методы и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все дальнейшие эксперименты предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print col_name, len(data[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре.\n",
    "\n",
    "Проще всего будет определить метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html), после чего воспользоваться реализацией kNN из sklearn (в этом случае используйте функцию predict_proba). Можно реализовать метод k ближайших соседей и самостоятально — в этом случае учитите, что он должен возвращать оценку вероятности, то есть отношение объектов первого класса среди соседей к числу соседей).\n",
    "\n",
    "Постарайтесь уделить особое внимание эффективности кода — при реализации метрик \"в лоб\" вы можете столкнуться с очень большим временем выполнения.\n",
    "\n",
    "#### Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Мера качества — AUC-ROC.\n",
    "\n",
    "#### Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hash_sid = np.empty((9), dtype=dict)\n",
    "Hash_id = np.empty((9), dtype=dict)\n",
    "L = len(X_train)\n",
    "for i, feature in enumerate(X_train.columns):\n",
    "    Hash_sid[i] = {}\n",
    "    Hash_id[i] = {}\n",
    "F = X_train[feature].value_counts()\n",
    "feature_values = X_train[feature].unique()\n",
    "for x in feature_values:\n",
    "    Hash_sid[i][x] = F[x] * (F[x] - 1) / (L * (L - 1))\n",
    "    Hash_id[i][x] = math.log(F[x] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_dist(x, y):\n",
    "    return (x != y).sum()\n",
    "def smoothy_indicator_dist(x, y):\n",
    "    return np.array([(x[c] != y[c]) + (x[c] == y[c]) * Hash_sid[c].get(x[c], 0) for c in range(9)]).sum()\n",
    "def importance_dist(x, y):\n",
    "    return np.array([(x[c] != y[c]) * Hash_id[c].get(x[c], 0) * Hash_id[c].get(y[c], 0) for c in range(9)]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm=\"brute\", metric=indicator_dist).fit(X_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm=\"brute\", metric=smoothy_indicator_dist).fit(X_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10, algorithm=\"brute\", metric=importance_dist).fit(X_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось получить?\n",
    "\n",
    "Для подбора можно использовать любые средства из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeCounters(train, extractable_data, extractable_data_ans):\n",
    "        train_modified = pd.DataFrame(index=train.index)\n",
    "        for feature in train.columns:\n",
    "            vc = extractable_data[feature].value_counts()\n",
    "            vc_t = (extractable_data[feature] * extractable_data_ans).value_counts()\n",
    "            train_modified[feature + \"_counts\"] = pd.Series([vc.get(x, 0) for x in train[feature]], index=train.index),\n",
    "            train_modified[feature + \"_successes\"] = pd.Series([vc_t.get(x, 0) for x in train[feature]], index=train.index)\n",
    "    train_modified[feature + \"_cs\"] = (train_modified[feature + \"_successes\"] + 1) / (train_modified[feature + \"_counts\"] + 2)\n",
    "        return train_modified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`successes` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанные по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_train = MakeCounters(X_train, X_train, y_train)\n",
    "mod_test = MakeCounters(X_test, X_train, y_train)\n",
    "k_list = np.arange(1, 20)\n",
    "auc_roc = np.empty(k_list.shape)\n",
    "for i, k in enumerate(k_list):\n",
    "    Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k, algorithm=\"kd_tree\").fit(mod_train, y_train)\n",
    "    auc_roc[i] = sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(mod_test)[:, 1])\n",
    "plt.plot(k_list, auc_roc)\n",
    "plt.show()\n",
    "print(\"BEST k: \", k_list[np.argmax(auc_roc)])\n",
    "print(\"BEST AUC-ROC: \", np.max(auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = len(X_train)\n",
    "mt1 = MakeCounters(X_train[:L//3], X_train[L//3:], y_train[L//3:])\n",
    "indexes = np.append(np.arange(0, L//3), np.arange(2*L//3, L))\n",
    "mt2 = MakeCounters(X_train[L//3:2*L//3], X_train.iloc[indexes], y_train.iloc[indexes])\n",
    "mt3 = MakeCounters(X_train[2*L//3:], X_train[:2*L//3], y_train[:2*L//3])\n",
    "mt = pd.concat([mt1, mt2, mt3])\n",
    "for feature in mt.columns[np.arange(0, len(mt.columns), 3)]:\n",
    "     mt[feature] *= 3 / 2\n",
    "for feature in mt.columns[np.arange(1, len(mt.columns), 3)]:\n",
    "    mt[feature] *= 3 / 2\\\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_train = MakeCountersWithFolding(X_train, y_train)\n",
    "mod_test = MakeCounters(X_test, X_train, y_train)\n",
    "k_list = np.arange(1, 25)\n",
    "auc_roc = np.empty(k_list.shape)\n",
    "for i, k in enumerate(k_list):\n",
    "    Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k, algorithm=\\\"kd_tree\\\").fit(mod_train, y_train)\n",
    "    auc_roc[i] = sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(mod_test)[:, 1])\n",
    "plt.plot(k_list, auc_roc)\n",
    "plt.show()\n",
    "print(\"BEST k: \", k_list[np.argmax(auc_roc)])\n",
    "print(\"BEST AUC-ROC: \", np.max(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $(f_i, f_j)$, $i < j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$ (желательно через какой-нибудь специальный символ во избежание коллизий). Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakePairFeatures(train):\n",
    "train_modified = train.copy()\n",
    "for i, feature1 in enumerate(train.columns):\n",
    "    for feature2 in train.columns[i+1:]:\n",
    "    train_modified[feature1 + \"+\" + feature2] = train[feature1].astype(str) + \"#\" + train[feature2].astype(str)\n",
    "return train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = MakePairFeatures(X_train), MakePairFeatures(X_test)\n",
    "mod_train_wf = MakeCountersWithFolding(train, y_train)\n",
    "mod_test_wf = MakeCounters(test, train, y_train)\n",
    "k_list = np.arange(5, 25)\n",
    "auc_roc = np.empty(k_list.shape)\n",
    "for i, k in enumerate(k_list):\n",
    "    Classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k, algorithm=\"kd_tree\", n_jobs = -1).fit(mod_train_wf, y_train)\n",
    "    auc_roc[i] = sklearn.metrics.roc_auc_score(y_test, Classifier.predict_proba(mod_test_wf)[:, 1])\n",
    "plt.plot(k_list, auc_roc)\n",
    "plt.show()\n",
    "print(\"BEST k: \", k_list[np.argmax(auc_roc)])\n",
    "print(\"BEST AUC-ROC: \", np.max(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = np.arange(4, 30)\n",
    "samples_leaf = np.arange(8, 20).astype(int)\n",
    "xgrid, ygrid = np.meshgrid(depth, samples_leaf)\n",
    "zgrid = np.zeros(xgrid.shape)\n",
    "for sl in range(len(samples_leaf)):\n",
    "    for d in range(len(depth)):\n",
    "        for test_k in range(5):\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=depth[d], min_samples_leaf=samples_leaf[sl])\n",
    "            clf = clf.fit(mod_train, y_train)\n",
    "            zgrid[sl][d] += sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test)[:, 1])\n",
    "            zgrid[sl][d] /= 5\n",
    "plt.pcolor(xgrid, ygrid, zgrid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=26, min_samples_leaf=13)\n",
    "clf = clf.fit(mod_train, y_train)\n",
    "print(sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав такое число деревьев `n_estimators`, при котором ошибка выходит на асимптоту. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_set = np.arange(1, 20)\n",
    "results = np.zeros(n_set.shape[0])\n",
    "overfitting = np.zeros(n_set.shape[0])\n",
    "for i, n in enumerate(n_set):\n",
    "    for k in range(5):\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators = n, max_depth=8, min_samples_leaf=15, n_jobs = -1)\n",
    "        clf = clf.fit(mod_train_wf, y_train)\n",
    "        results[i] += sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test_wf)[:, 1])\n",
    "        overfitting[i] += sklearn.metrics.roc_auc_score(y_train, clf.predict_proba(mod_train_wf)[:, 1])\n",
    "        results[i] /= 5\n",
    "        overfitting[i] /= 5\n",
    "plt.plot(n_set, results)\n",
    "plt.plot(n_set, overfitting)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators = 16, max_depth=8, min_samples_leaf=15, n_jobs = -1)\n",
    "clf = clf.fit(mod_train_wf, y_train)\n",
    "print(\"FINAL RESULT: \", sklearn.metrics.roc_auc_score(y_test, clf.predict_proba(mod_test_wf)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями о задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ооочень сложная лабораторная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь посоветуйте преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Миллионер из трущоб"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
